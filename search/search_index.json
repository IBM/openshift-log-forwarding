{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00b6 Workshop Title \u00b6 Welcome to our workshop! In this workshop we'll be using foo to accomplish bar. The goals of this workshop are: Goals! Have fun! About this workshop \u00b6 The introductory page of the workshop is broken down into the following sections: Agenda Compatibility Technology Used Credits Agenda \u00b6 Lab 0: Pre-work Pre-work for the project Lab 1: Some Title Exercise to do the thing Compatibility \u00b6 This workshop has been tested on the following platforms: osName : version X, version Y Technology Used \u00b6 Brief Description Credits \u00b6 Full Name","title":"About the workshop"},{"location":"#introduction","text":"","title":"Introduction"},{"location":"#workshop-title","text":"Welcome to our workshop! In this workshop we'll be using foo to accomplish bar. The goals of this workshop are: Goals! Have fun!","title":"Workshop Title"},{"location":"#about-this-workshop","text":"The introductory page of the workshop is broken down into the following sections: Agenda Compatibility Technology Used Credits","title":"About this workshop"},{"location":"#agenda","text":"Lab 0: Pre-work Pre-work for the project Lab 1: Some Title Exercise to do the thing","title":"Agenda"},{"location":"#compatibility","text":"This workshop has been tested on the following platforms: osName : version X, version Y","title":"Compatibility"},{"location":"#technology-used","text":"Brief Description","title":"Technology Used"},{"location":"#credits","text":"Full Name","title":"Credits"},{"location":"lab-1/","text":"Forwarding logs to an external logging platform \u00b6 In this workshop we will explore how to forward logs to an external logging platform through the built in OpenShift Logging service. For this workshop, the logging platform that we will be forwarding to is Spunk, however, for workshop purposes this instance of Splunk will actually also be deployed on your OpenShift cluster. 1. Setup \u00b6 Clone the repo git clone https://github.com/odrodrig/openshift-logforwarding-splunk.git cd openshift-logforwarding-splunk In the Cloud Shell , download and unzip Helm v3.2. cd $HOME wget https://get.helm.sh/helm-v3.2.0-linux-amd64.tar.gz tar -zxvf helm-v3.2.0-linux-amd64.tar.gz Make Helm v3 CLI available in your PATH environment variable. echo 'export PATH=$HOME/linux-amd64:$PATH' > $HOME/.bash_profile source $HOME/.bash_profile Verify Helm v3 installation. helm version --short outputs, $ helm version --short v3.2.0+ge11b7ce 1. Deploy OpenShift Logging \u00b6 In OpenShift with the OpenShift Logging operator you are able to create an instance of the EFK stack which includes Elasticsearch for storing logs, Fluentd for collecting logs, and Kibana for displaying logs. We will be exploring how to utilize the built-in EFK stack to gather logs and forward them to Splunk. In order to forward the logs to Splunk we will need to forward the logs using Fluentd. While the EFK stack includes an instance of Fluentd already, we need to configure a standalone instance of Fluentd to act as our forwarding service to send logs to Splunk. This process can be done through the OpenShift web console or through the cli. For the purposes of this workshop, we will be using yaml files with the cli to set everything up for us. First we need to create projects for our OpenShift logging operator and for the Elasticsearch operator. oc apply -f prereqs/projects.yaml Next, we will need to create the operators. This is done by creating an OperatorGroup and a subscription to both the Elasticsearch operator and the OpenShift Logging operator. oc apply -f prereqs/operators.yaml Before we proceed we need to verify that the operators are deployed. This is done by looking at the ClusterServiceVersion that was deployed for the Operator when we created the subscriptions. Ensure that for both operators the PHASE column reads Succeeded . This will take a minute to complete. If you try too early you might see a message that says No resources found in openshift-logging namespace. oc get csv -n openshift-logging NAME DISPLAY VERSION REPLACES PHASE cluster-logging.5.2.2-21 Red Hat OpenShift Logging 5 .2.2-21 Succeeded elasticsearch-operator.5.1.2-7 OpenShift Elasticsearch Operator 5 .1.2-7 Succeeded With the OpenShift Logging operator deployed we now need to create our ClusterLogging instance. Before we run the command to create it, let's take a look at the clusterLogging.yaml file: apiVersion : \"logging.openshift.io/v1\" kind : \"ClusterLogging\" metadata : name : \"instance\" namespace : \"openshift-logging\" spec : managementState : \"Managed\" # logStore: # type: \"elasticsearch\" # retentionPolicy: # application: # maxAge: 1d # infra: # maxAge: 7d # audit: # maxAge: 7d # elasticsearch: # nodeCount: 3 # storage: # storageClassName: \"ibmc-block-gold\" # size: 200G # resources: # requests: # memory: \"8Gi\" # proxy: # resources: # limits: # memory: 256Mi # requests: # memory: 256Mi # redundancyPolicy: \"SingleRedundancy\" # visualization: # type: \"kibana\" # kibana: # replicas: 1 collection : logs : type : \"fluentd\" fluentd : {} This ClusterLogging object has three key areas: logStore, visualization, and collection. These correspond to the components of the EFK stack as seen below: logStore = **E**lasticsearch collection = **F**luentd visualization = **K**ibana For our lab we are not focusing on using the Elasticsearch and Kibana portions of the clusterLogging object so we have commented them out which will disable them on our cluster. We are only interested in the Fluentd component which allows for log collection and forwarding. Note: For this workshop we are using clusters with minimal resources which will not support Elasticsearch's memory requirements. Let's go ahead and deploy our ClusterLogging instance now: oc apply -f prereqs/clusterLogging.yaml -n openshift-logging Before we continue we will need to verify that the fluentd pods are running oc get pods -n openshift-logging Ensure that the 3 fluentd pods all have a status of Running before continuing. With the fluentd pods running, now we can install splunk. 2. Configuring Splunk \u00b6 As mentioned before, for the purposes of this workshop we will be installing Splunk locally on your OpenShift clusters. Run the following script to install Splunk: ./splunk_install.sh This will take a moment to complete. Next, let's log in to our Splunk instance through our browser. Run the following to find the address for Splunk: oc get routes -n splunk Then copy the address that appears. It should be listed under the HOST/PORT section and start with splunk-splunk... . An example can be seen below: ```bash NAME HOST/PORT PATH SERVICES PORT TERMINATION WILDCARD splunk splunk-splunk.oliver-logging-2bef1f4b4097001da9502000c44fc2b2-0000.us-south.containers.appdomain.cloud splunk 8000 edge/Redirect None Paste the address that you copied from the earlier command in to your browser in a new tab. This will take you to the Splunk instance that is running in your cluster. You should then see a log in page. Use the following credentials to log in: username: admin password: admin123 If asked about Making Spunk Better, click on Skip. If you are asked about taking a product tour, click on Do not remind me again. Before we send logs to Splunk we need to create an index which will allow us to store log data relating to our cluster. A Splunk index is just a repository for data coming into Splunk. From the Splunk main page, click on Settings at the top right of the page and select Indexes On the next page, select the New Index button On the form that appears, name the index openshift and click on the Save button on the bottom of the page. With our Splunk instance created and configured we now will need to create our standalone instance of Fluentd that will forward the logs. 3. Deploying the Fluentd Forwarder \u00b6 With OpenShift Logging we gain the ability to forward logs to an external logging solution that supports the following: Elasticsearch FluentForward Syslog Kafka Since Splunk isn't available to forward to out of the box, we will need to set up an instance of Fluentd that we can use the FluentForward protocol with to send the logs to which we then will configure to send the logs to Splunk. Install the Fluentd Forwarder with the following command helm install --namespace = openshift-logging openshift-logforwarding-splunk charts/openshift-logforwarding-splunk/ --set forwarding.splunk.token = 4a8a737d-5452-426c-a6f7-106dca4e813f The token value above should be the same for everybody. This value was taken from the assets/helm/values/splunk_install.yaml file. Check to see that the openshift-logforwarding pods are running by using the following command: oc get pods -n openshift-logging This fluentd instance is already configured to forward logs to your splunk instance. This is done through a ConfigMap that contains the information needed to connect with Splunk. To view this configMap, use the following command. oc describe configmap openshift-logforwarding-splunk -n openshift-logging This information is passed into the fluentd forwarder pods upon creation. The template used to create this configmap can be found in the repo cloned earlier in the /charts/openshift-logforwarding-splunk/templates/log-forwarding-splunk-configmap.yaml file. That helm chart not only deployed the fluentd forwarding pods but it also created a ClusterLogForwarder object. This Custom Resource is managed by the OpenShift Logging Operator that was installed earlier. The ClusterLogForwarder allows us to forward logs using any of the methods mentioned at the beginning of this section. For our purposes, we will be forwarding using the fluentForward method. Let's take a look at the ClusterLogForwarder object that was created: oc describe clusterlogforwarder instance -n openshift-logging Take a look at the spec fields: Spec : Outputs : Name : openshift-logforwarding-splunk Secret : Name : openshift-logforwarding-splunk Type : fluentdForward URL : tls://openshift-logforwarding-splunk.openshift-logging.svc:24224 Pipelines : Input Refs : application Name : container-logs Output Refs : default openshift-logforwarding-splunk Input Refs : infrastructure Name : infra-logs Output Refs : default openshift-logforwarding-splunk From this object we are defining a few things: Outputs: We are pointing to our newly created openshift-logforwarding-splunk instance of fluentd that was created by the helm chart. Pipelines: We have 2 pipelines which relate to 2 different kinds of logs that we are forwarding: Application logs and infrastructure logs. Notice the Output Refs that are defined. default refers to the built in instance of Elasticsearch that is running on the cluster as part of OpenShift Logging while the openshift-logforwarding-splunk refers to the output defined above which points to the fluentd forwarding instance. Before we generate some logs to send over, we need to enable log forwarding. This is done through an annotation to the ClusterLogging object that we created at the beginning of the lab. oc annotate clusterlogging -n openshift-logging instance clusterlogging.openshift.io/logforwardingtechpreview = enabled With the Fluentd Forwarder in place and log forwarding enabled, we can now generate some logs to forward. 4. Forwarding logs \u00b6 Now let's test out everything we have set up by generating some logs Create a project where our test application will reside: oc new-project ruby-app Then create a test ruby application oc new-app ruby~https://github.com/sclorg/ruby-ex.git With that a new Ruby application will start to build and generate logs as it goes along. Go back to your browser tab that has Splunk and click on the Apps button at the top left of the page and select Search & Reporting . This is the page where we can sort through logs that have been sent over. In the search box, enter the following: index = \"openshift\" kubernetes.namespace_name = ruby-app | table _time kubernetes.namespace_name kubernetes.pod_name message | sort -_time What this search allows us to do is 3 things: - Search for all events from our openshift index and namespace named ruby-app - Create a table with the time of event, namespace the event occurred in, the name of the pod generating the message, and the log message itself. - Sort the table in descending order of when the even occurred with the newest events at the top. These are application logs returned from the running container we created. To view all application logs, you can try the following search: index = \"openshift\" log_type = \"application\" | table _time kubernetes.namespace_name kubernetes.pod_name message | sort -_time How about logs pertaining to the health of the actual OpenShift cluster? Try the following search: index = \"openshift\" log_type = \"infrastructure\" | table _time kubernetes.namespace_name kubernetes.pod_name message | sort -_time This search returns infrastructure logs which are generated from OpenShift components in specific namespaces such as openshift-operator-lifecycle-manager, openshift-network-diagnostics, openshift-monitoring, openshift-image-registry, kube-system, and more. Conclusion \u00b6 In this lab we explored OpenShift Logging and how to forward logs to an external logging solution. We deployed Splunk to our cluster and configured a standalone Fluentd instance to forward logs to Splunk. Then, we enabled Log Forwarding and generated some logs to send over to Splunk. Finally, we explored the events that were sent over to Splunk and viewed both application and infrastructure logs from our cluster.","title":"Lab 1. Some Title"},{"location":"lab-1/#forwarding-logs-to-an-external-logging-platform","text":"In this workshop we will explore how to forward logs to an external logging platform through the built in OpenShift Logging service. For this workshop, the logging platform that we will be forwarding to is Spunk, however, for workshop purposes this instance of Splunk will actually also be deployed on your OpenShift cluster.","title":"Forwarding logs to an external logging platform"},{"location":"lab-1/#1-setup","text":"Clone the repo git clone https://github.com/odrodrig/openshift-logforwarding-splunk.git cd openshift-logforwarding-splunk In the Cloud Shell , download and unzip Helm v3.2. cd $HOME wget https://get.helm.sh/helm-v3.2.0-linux-amd64.tar.gz tar -zxvf helm-v3.2.0-linux-amd64.tar.gz Make Helm v3 CLI available in your PATH environment variable. echo 'export PATH=$HOME/linux-amd64:$PATH' > $HOME/.bash_profile source $HOME/.bash_profile Verify Helm v3 installation. helm version --short outputs, $ helm version --short v3.2.0+ge11b7ce","title":"1. Setup"},{"location":"lab-1/#1-deploy-openshift-logging","text":"In OpenShift with the OpenShift Logging operator you are able to create an instance of the EFK stack which includes Elasticsearch for storing logs, Fluentd for collecting logs, and Kibana for displaying logs. We will be exploring how to utilize the built-in EFK stack to gather logs and forward them to Splunk. In order to forward the logs to Splunk we will need to forward the logs using Fluentd. While the EFK stack includes an instance of Fluentd already, we need to configure a standalone instance of Fluentd to act as our forwarding service to send logs to Splunk. This process can be done through the OpenShift web console or through the cli. For the purposes of this workshop, we will be using yaml files with the cli to set everything up for us. First we need to create projects for our OpenShift logging operator and for the Elasticsearch operator. oc apply -f prereqs/projects.yaml Next, we will need to create the operators. This is done by creating an OperatorGroup and a subscription to both the Elasticsearch operator and the OpenShift Logging operator. oc apply -f prereqs/operators.yaml Before we proceed we need to verify that the operators are deployed. This is done by looking at the ClusterServiceVersion that was deployed for the Operator when we created the subscriptions. Ensure that for both operators the PHASE column reads Succeeded . This will take a minute to complete. If you try too early you might see a message that says No resources found in openshift-logging namespace. oc get csv -n openshift-logging NAME DISPLAY VERSION REPLACES PHASE cluster-logging.5.2.2-21 Red Hat OpenShift Logging 5 .2.2-21 Succeeded elasticsearch-operator.5.1.2-7 OpenShift Elasticsearch Operator 5 .1.2-7 Succeeded With the OpenShift Logging operator deployed we now need to create our ClusterLogging instance. Before we run the command to create it, let's take a look at the clusterLogging.yaml file: apiVersion : \"logging.openshift.io/v1\" kind : \"ClusterLogging\" metadata : name : \"instance\" namespace : \"openshift-logging\" spec : managementState : \"Managed\" # logStore: # type: \"elasticsearch\" # retentionPolicy: # application: # maxAge: 1d # infra: # maxAge: 7d # audit: # maxAge: 7d # elasticsearch: # nodeCount: 3 # storage: # storageClassName: \"ibmc-block-gold\" # size: 200G # resources: # requests: # memory: \"8Gi\" # proxy: # resources: # limits: # memory: 256Mi # requests: # memory: 256Mi # redundancyPolicy: \"SingleRedundancy\" # visualization: # type: \"kibana\" # kibana: # replicas: 1 collection : logs : type : \"fluentd\" fluentd : {} This ClusterLogging object has three key areas: logStore, visualization, and collection. These correspond to the components of the EFK stack as seen below: logStore = **E**lasticsearch collection = **F**luentd visualization = **K**ibana For our lab we are not focusing on using the Elasticsearch and Kibana portions of the clusterLogging object so we have commented them out which will disable them on our cluster. We are only interested in the Fluentd component which allows for log collection and forwarding. Note: For this workshop we are using clusters with minimal resources which will not support Elasticsearch's memory requirements. Let's go ahead and deploy our ClusterLogging instance now: oc apply -f prereqs/clusterLogging.yaml -n openshift-logging Before we continue we will need to verify that the fluentd pods are running oc get pods -n openshift-logging Ensure that the 3 fluentd pods all have a status of Running before continuing. With the fluentd pods running, now we can install splunk.","title":"1. Deploy OpenShift Logging"},{"location":"lab-1/#2-configuring-splunk","text":"As mentioned before, for the purposes of this workshop we will be installing Splunk locally on your OpenShift clusters. Run the following script to install Splunk: ./splunk_install.sh This will take a moment to complete. Next, let's log in to our Splunk instance through our browser. Run the following to find the address for Splunk: oc get routes -n splunk Then copy the address that appears. It should be listed under the HOST/PORT section and start with splunk-splunk... . An example can be seen below: ```bash NAME HOST/PORT PATH SERVICES PORT TERMINATION WILDCARD splunk splunk-splunk.oliver-logging-2bef1f4b4097001da9502000c44fc2b2-0000.us-south.containers.appdomain.cloud splunk 8000 edge/Redirect None Paste the address that you copied from the earlier command in to your browser in a new tab. This will take you to the Splunk instance that is running in your cluster. You should then see a log in page. Use the following credentials to log in: username: admin password: admin123 If asked about Making Spunk Better, click on Skip. If you are asked about taking a product tour, click on Do not remind me again. Before we send logs to Splunk we need to create an index which will allow us to store log data relating to our cluster. A Splunk index is just a repository for data coming into Splunk. From the Splunk main page, click on Settings at the top right of the page and select Indexes On the next page, select the New Index button On the form that appears, name the index openshift and click on the Save button on the bottom of the page. With our Splunk instance created and configured we now will need to create our standalone instance of Fluentd that will forward the logs.","title":"2. Configuring Splunk"},{"location":"lab-1/#3-deploying-the-fluentd-forwarder","text":"With OpenShift Logging we gain the ability to forward logs to an external logging solution that supports the following: Elasticsearch FluentForward Syslog Kafka Since Splunk isn't available to forward to out of the box, we will need to set up an instance of Fluentd that we can use the FluentForward protocol with to send the logs to which we then will configure to send the logs to Splunk. Install the Fluentd Forwarder with the following command helm install --namespace = openshift-logging openshift-logforwarding-splunk charts/openshift-logforwarding-splunk/ --set forwarding.splunk.token = 4a8a737d-5452-426c-a6f7-106dca4e813f The token value above should be the same for everybody. This value was taken from the assets/helm/values/splunk_install.yaml file. Check to see that the openshift-logforwarding pods are running by using the following command: oc get pods -n openshift-logging This fluentd instance is already configured to forward logs to your splunk instance. This is done through a ConfigMap that contains the information needed to connect with Splunk. To view this configMap, use the following command. oc describe configmap openshift-logforwarding-splunk -n openshift-logging This information is passed into the fluentd forwarder pods upon creation. The template used to create this configmap can be found in the repo cloned earlier in the /charts/openshift-logforwarding-splunk/templates/log-forwarding-splunk-configmap.yaml file. That helm chart not only deployed the fluentd forwarding pods but it also created a ClusterLogForwarder object. This Custom Resource is managed by the OpenShift Logging Operator that was installed earlier. The ClusterLogForwarder allows us to forward logs using any of the methods mentioned at the beginning of this section. For our purposes, we will be forwarding using the fluentForward method. Let's take a look at the ClusterLogForwarder object that was created: oc describe clusterlogforwarder instance -n openshift-logging Take a look at the spec fields: Spec : Outputs : Name : openshift-logforwarding-splunk Secret : Name : openshift-logforwarding-splunk Type : fluentdForward URL : tls://openshift-logforwarding-splunk.openshift-logging.svc:24224 Pipelines : Input Refs : application Name : container-logs Output Refs : default openshift-logforwarding-splunk Input Refs : infrastructure Name : infra-logs Output Refs : default openshift-logforwarding-splunk From this object we are defining a few things: Outputs: We are pointing to our newly created openshift-logforwarding-splunk instance of fluentd that was created by the helm chart. Pipelines: We have 2 pipelines which relate to 2 different kinds of logs that we are forwarding: Application logs and infrastructure logs. Notice the Output Refs that are defined. default refers to the built in instance of Elasticsearch that is running on the cluster as part of OpenShift Logging while the openshift-logforwarding-splunk refers to the output defined above which points to the fluentd forwarding instance. Before we generate some logs to send over, we need to enable log forwarding. This is done through an annotation to the ClusterLogging object that we created at the beginning of the lab. oc annotate clusterlogging -n openshift-logging instance clusterlogging.openshift.io/logforwardingtechpreview = enabled With the Fluentd Forwarder in place and log forwarding enabled, we can now generate some logs to forward.","title":"3. Deploying the Fluentd Forwarder"},{"location":"lab-1/#4-forwarding-logs","text":"Now let's test out everything we have set up by generating some logs Create a project where our test application will reside: oc new-project ruby-app Then create a test ruby application oc new-app ruby~https://github.com/sclorg/ruby-ex.git With that a new Ruby application will start to build and generate logs as it goes along. Go back to your browser tab that has Splunk and click on the Apps button at the top left of the page and select Search & Reporting . This is the page where we can sort through logs that have been sent over. In the search box, enter the following: index = \"openshift\" kubernetes.namespace_name = ruby-app | table _time kubernetes.namespace_name kubernetes.pod_name message | sort -_time What this search allows us to do is 3 things: - Search for all events from our openshift index and namespace named ruby-app - Create a table with the time of event, namespace the event occurred in, the name of the pod generating the message, and the log message itself. - Sort the table in descending order of when the even occurred with the newest events at the top. These are application logs returned from the running container we created. To view all application logs, you can try the following search: index = \"openshift\" log_type = \"application\" | table _time kubernetes.namespace_name kubernetes.pod_name message | sort -_time How about logs pertaining to the health of the actual OpenShift cluster? Try the following search: index = \"openshift\" log_type = \"infrastructure\" | table _time kubernetes.namespace_name kubernetes.pod_name message | sort -_time This search returns infrastructure logs which are generated from OpenShift components in specific namespaces such as openshift-operator-lifecycle-manager, openshift-network-diagnostics, openshift-monitoring, openshift-image-registry, kube-system, and more.","title":"4. Forwarding logs"},{"location":"lab-1/#conclusion","text":"In this lab we explored OpenShift Logging and how to forward logs to an external logging solution. We deployed Splunk to our cluster and configured a standalone Fluentd instance to forward logs to Splunk. Then, we enabled Log Forwarding and generated some logs to send over to Splunk. Finally, we explored the events that were sent over to Splunk and viewed both application and infrastructure logs from our cluster.","title":"Conclusion"},{"location":"pre-work/","text":"Pre-work \u00b6 This section is broken up into the following steps: Sign up for IBM Cloud Download or clone the repo 1. Sign up for IBM Cloud \u00b6 Ensure you have an IBM Cloud ID 2. Download or clone the repo \u00b6 Various parts of this workshop will require the attendee to upload files or run scripts that we've stored in the repository. So let's get that done early on, you'll need git on your laptop to clone the repository directly, or access to GitHub.com to download the zip file. To Download, go to the GitHub repo for this workshop and download the archived version of the workshop and extract it on your laptop. Alternately, run the following command: git clone https://github.com/IBM/workshop-template cd workshop-template","title":"Lab 0. Pre-work"},{"location":"pre-work/#pre-work","text":"This section is broken up into the following steps: Sign up for IBM Cloud Download or clone the repo","title":"Pre-work"},{"location":"pre-work/#1-sign-up-for-ibm-cloud","text":"Ensure you have an IBM Cloud ID","title":"1. Sign up for IBM Cloud"},{"location":"pre-work/#2-download-or-clone-the-repo","text":"Various parts of this workshop will require the attendee to upload files or run scripts that we've stored in the repository. So let's get that done early on, you'll need git on your laptop to clone the repository directly, or access to GitHub.com to download the zip file. To Download, go to the GitHub repo for this workshop and download the archived version of the workshop and extract it on your laptop. Alternately, run the following command: git clone https://github.com/IBM/workshop-template cd workshop-template","title":"2. Download or clone the repo"},{"location":"resources/ADMIN/","text":"Admin Guide \u00b6 This section is comprised of the following steps: Instructor Step 1. Instructor Step \u00b6 Things specific to instructors can go here.","title":"Admin Guide"},{"location":"resources/ADMIN/#admin-guide","text":"This section is comprised of the following steps: Instructor Step","title":"Admin Guide"},{"location":"resources/ADMIN/#1-instructor-step","text":"Things specific to instructors can go here.","title":"1. Instructor Step"},{"location":"resources/CONTRIBUTORS/","text":"Contributors \u00b6 Remko de Knikker \u00b6 Github: remkohdev Twitter: @remkohdev LinkedIn: remkohdev Medium: @remkohdev Steve Martinelli \u00b6 Github: stevemar Twitter: @stevebot LinkedIn: stevemar","title":"Contributors"},{"location":"resources/CONTRIBUTORS/#contributors","text":"","title":"Contributors"},{"location":"resources/CONTRIBUTORS/#remko-de-knikker","text":"Github: remkohdev Twitter: @remkohdev LinkedIn: remkohdev Medium: @remkohdev","title":"Remko de Knikker"},{"location":"resources/CONTRIBUTORS/#steve-martinelli","text":"Github: stevemar Twitter: @stevebot LinkedIn: stevemar","title":"Steve Martinelli"},{"location":"resources/MKDOCS/","text":"mkdocs examples \u00b6 This page includes a few neat tricks that you can do with mkdocs . For a complete list of examples visit the mkdocs documentation . Code \u00b6 print ( \"hello world!\" ) Code with line numbers \u00b6 1 2 3 4 5 def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] Code with highlights \u00b6 def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] Code with tabs \u00b6 Tab Header #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); return 0 ; } Another Tab Header #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; } More tabs \u00b6 Windows If on windows download the Win32.zip file and install it. MacOS Run brew install foo . Linux Run apt-get install foo . Checklists \u00b6 Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst Add a button \u00b6 Launch the lab Visit IBM Developer Sign up! Call outs \u00b6 Tip You can use note , abstract , info , tip , success , question warning , failure , danger , bug , quote or example . Note A note. Abstract An abstract. Info Some info. Success A success. Question A question. Warning A warning. Danger A danger. Example A example. Bug A bug. Call outs with code \u00b6 Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] Nunc eu odio eleifend, blandit leo a, volutpat sapien. Phasellus posuere in sem ut cursus. Nullam sit amet tincidunt ipsum, sit amet elementum turpis. Etiam ipsum quam, mattis in purus vitae, lacinia fermentum enim. Formatting \u00b6 In addition to the usual italics , and bold there is now support for: highlighted underlined strike-through Tables \u00b6 OS or Application Username Password Windows VM Administrator foo Linux VM root bar Emojis \u00b6 Yes, these work. Images \u00b6 Nunc eu odio eleifend, blandit leo a, volutpat sapien right align image \u00b6 Nunc eu odio eleifend, blandit leo a, volutpat sapien","title":"MkDocs Cheatsheet"},{"location":"resources/MKDOCS/#mkdocs-examples","text":"This page includes a few neat tricks that you can do with mkdocs . For a complete list of examples visit the mkdocs documentation .","title":"mkdocs examples"},{"location":"resources/MKDOCS/#code","text":"print ( \"hello world!\" )","title":"Code"},{"location":"resources/MKDOCS/#code-with-line-numbers","text":"1 2 3 4 5 def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ]","title":"Code with line numbers"},{"location":"resources/MKDOCS/#code-with-highlights","text":"def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ]","title":"Code with highlights"},{"location":"resources/MKDOCS/#code-with-tabs","text":"Tab Header #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); return 0 ; } Another Tab Header #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; }","title":"Code with tabs"},{"location":"resources/MKDOCS/#more-tabs","text":"Windows If on windows download the Win32.zip file and install it. MacOS Run brew install foo . Linux Run apt-get install foo .","title":"More tabs"},{"location":"resources/MKDOCS/#checklists","text":"Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst","title":"Checklists"},{"location":"resources/MKDOCS/#add-a-button","text":"Launch the lab Visit IBM Developer Sign up!","title":"Add a button"},{"location":"resources/MKDOCS/#call-outs","text":"Tip You can use note , abstract , info , tip , success , question warning , failure , danger , bug , quote or example . Note A note. Abstract An abstract. Info Some info. Success A success. Question A question. Warning A warning. Danger A danger. Example A example. Bug A bug.","title":"Call outs"},{"location":"resources/MKDOCS/#call-outs-with-code","text":"Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] Nunc eu odio eleifend, blandit leo a, volutpat sapien. Phasellus posuere in sem ut cursus. Nullam sit amet tincidunt ipsum, sit amet elementum turpis. Etiam ipsum quam, mattis in purus vitae, lacinia fermentum enim.","title":"Call outs with code"},{"location":"resources/MKDOCS/#formatting","text":"In addition to the usual italics , and bold there is now support for: highlighted underlined strike-through","title":"Formatting"},{"location":"resources/MKDOCS/#tables","text":"OS or Application Username Password Windows VM Administrator foo Linux VM root bar","title":"Tables"},{"location":"resources/MKDOCS/#emojis","text":"Yes, these work.","title":"Emojis"},{"location":"resources/MKDOCS/#images","text":"Nunc eu odio eleifend, blandit leo a, volutpat sapien","title":"Images"},{"location":"resources/MKDOCS/#right-align-image","text":"Nunc eu odio eleifend, blandit leo a, volutpat sapien","title":"right align image"},{"location":"resources/RESOURCES/","text":"Additional resources \u00b6 IBM Demos \u00b6 Collection: InfoSphere Information Server Tutorial: Transforming your data with IBM DataStage Redbooks \u00b6 IBM InfoSphere DataStage Data Flow and Job Design InfoSphere DataStage Parallel Framework Standard Practices Videos \u00b6 Video: Postal codes and part numbers (DataStage) Video: Find relationships between sales, employees, and customers (Information Analyzer) Video: Clean and analyze data (Governance Catalog)","title":"Additional Resources"},{"location":"resources/RESOURCES/#additional-resources","text":"","title":"Additional resources"},{"location":"resources/RESOURCES/#ibm-demos","text":"Collection: InfoSphere Information Server Tutorial: Transforming your data with IBM DataStage","title":"IBM Demos"},{"location":"resources/RESOURCES/#redbooks","text":"IBM InfoSphere DataStage Data Flow and Job Design InfoSphere DataStage Parallel Framework Standard Practices","title":"Redbooks"},{"location":"resources/RESOURCES/#videos","text":"Video: Postal codes and part numbers (DataStage) Video: Find relationships between sales, employees, and customers (Information Analyzer) Video: Clean and analyze data (Governance Catalog)","title":"Videos"}]}